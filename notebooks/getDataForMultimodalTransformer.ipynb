{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from src.data import download_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data and sort it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('data/reviewed_data_5_13_24.csv') ##We can use this for training\n",
    "data = pd.read_csv('../data/final_eval_data.csv')\n",
    "# data = pd.read_csv('data/justin_dataset_may_models.csv').rename(columns={'new_url': 'download_url'}) ##This we can use to bolster the R rated dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "PG       7393\n",
       "PG13    13425\n",
       "R        5557\n",
       "X        7622\n",
       "XXX      6007\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lj/vxfv4wp1351_qdc939xvvn0m0000gn/T/ipykernel_6898/3553324668.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  balanced_data = data.groupby('label').apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "PG      5557\n",
       "PG13    5557\n",
       "R       5557\n",
       "X       5557\n",
       "XXX     5557\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of rows per label\n",
    "label_counts = data.groupby('label')['label'].count()\n",
    "\n",
    "# Get the minimum count among all labels\n",
    "min_count = label_counts.min()\n",
    "\n",
    "# Sample equal number of rows per label\n",
    "balanced_data = data.groupby('label').apply(lambda x: x.sample(n=min_count, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "balanced_data.groupby('label')['label'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>download_url</th>\n",
       "      <th>prompt</th>\n",
       "      <th>tags</th>\n",
       "      <th>label</th>\n",
       "      <th>datatype</th>\n",
       "      <th>mixtureModel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...</td>\n",
       "      <td>Generate a photograph of a realistic modern wo...</td>\n",
       "      <td>beachwear, clothing, blonde, hair, person, adu...</td>\n",
       "      <td>PG</td>\n",
       "      <td>justins_eval</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...</td>\n",
       "      <td>Gerudo Link, gerudolink, blonde, green see-thr...</td>\n",
       "      <td>man, blonde hair, blue eyes, crossdressing, de...</td>\n",
       "      <td>PG</td>\n",
       "      <td>justins_eval</td>\n",
       "      <td>PG13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...</td>\n",
       "      <td>photo of beautiful woman with perfect (red col...</td>\n",
       "      <td>body freckles, nose, realistic, freckles, lips...</td>\n",
       "      <td>PG</td>\n",
       "      <td>training</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...</td>\n",
       "      <td>score_9, score_8_up, score_7_up, a red haired ...</td>\n",
       "      <td>woman, cartoon, head, face, person, publicatio...</td>\n",
       "      <td>PG</td>\n",
       "      <td>training</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...</td>\n",
       "      <td>what do you want from me</td>\n",
       "      <td>solo, strapless, realistic, parted lips, looki...</td>\n",
       "      <td>PG</td>\n",
       "      <td>training</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        download_url  \\\n",
       "0  https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...   \n",
       "1  https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...   \n",
       "2  https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...   \n",
       "3  https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...   \n",
       "4  https://image.civitai.com/xG1nkqKTMzGDvpLrqFT7...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  Generate a photograph of a realistic modern wo...   \n",
       "1  Gerudo Link, gerudolink, blonde, green see-thr...   \n",
       "2  photo of beautiful woman with perfect (red col...   \n",
       "3  score_9, score_8_up, score_7_up, a red haired ...   \n",
       "4                           what do you want from me   \n",
       "\n",
       "                                                tags label      datatype  \\\n",
       "0  beachwear, clothing, blonde, hair, person, adu...    PG  justins_eval   \n",
       "1  man, blonde hair, blue eyes, crossdressing, de...    PG  justins_eval   \n",
       "2  body freckles, nose, realistic, freckles, lips...    PG      training   \n",
       "3  woman, cartoon, head, face, person, publicatio...    PG      training   \n",
       "4  solo, strapless, realistic, parted lips, looki...    PG      training   \n",
       "\n",
       "  mixtureModel  \n",
       "0           PG  \n",
       "1         PG13  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "# Iterate over the DataFrame\n",
    "for index, row in balanced_data.iterrows():\n",
    "    data[index] = {\n",
    "        \"url\": row['download_url'], \n",
    "        \"prompt\": row['prompt'],\n",
    "        \"tags\": f\"{row['tags']}\",\n",
    "        \"label\": row['label']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'prompt_and_tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/datasets/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdownload_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/civitai/projects/compositeModalTransformer/notebooks/../src/data.py:96\u001b[0m, in \u001b[0;36mdownload_images\u001b[0;34m(imageUrlDict, output_dir, max_workers)\u001b[0m\n\u001b[1;32m     93\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(executor\u001b[38;5;241m.\u001b[39msubmit(get_data_for_training, data_item, output_dir))\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/python3.12.4/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/local/python3.12.4/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/python3.12.4/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/civitai/projects/compositeModalTransformer/notebooks/../src/data.py:57\u001b[0m, in \u001b[0;36mget_data_for_training\u001b[0;34m(data_item, output_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m url \u001b[38;5;241m=\u001b[39m data_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     56\u001b[0m prompt \u001b[38;5;241m=\u001b[39m data_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 57\u001b[0m prompt_and_tags \u001b[38;5;241m=\u001b[39m \u001b[43mdata_item\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprompt_and_tags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     58\u001b[0m folder \u001b[38;5;241m=\u001b[39m data_item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'prompt_and_tags'"
     ]
    }
   ],
   "source": [
    "output = './data/datasets/'\n",
    "download_images(data, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PG imgs: 340\n",
      "PG text: 340\n",
      "PG tags: 317\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir(output):\n",
    "    path = os.path.join(output, i)\n",
    "    print(i, f\"imgs: {len([i for i in os.listdir(path) if i.endswith('.jpg')])}\")\n",
    "    print(i, f\"text: {len([i for i in os.listdir(path) if i.endswith('.txt') and 'tags' not in i])}\")\n",
    "    print(i, f\"tags: {len([i for i in os.listdir(path) if i.endswith('.txt') and 'tags' in i])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use loop for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the source directory containing class-specific folders\n",
    "# source_dir = './data/training_data/'\n",
    "\n",
    "# # Define the output directories for training and validation\n",
    "# output_train_dir = './data/datasets/may/train'\n",
    "# output_val_dir = './data/datasets/may/val'\n",
    "\n",
    "# # Create the output directories if they don't exist\n",
    "# os.makedirs(output_train_dir, exist_ok=True)\n",
    "# os.makedirs(output_val_dir, exist_ok=True)\n",
    "\n",
    "# # Iterate over each class-specific folder\n",
    "# for class_name in os.listdir(source_dir):\n",
    "#     class_path = os.path.join(source_dir, class_name)\n",
    "    \n",
    "#     if os.path.isdir(class_path):\n",
    "#         # List of all .txt files (excluding those with 'tags' in their name)\n",
    "#         txt_files = [f for f in os.listdir(class_path) if f.endswith('.txt') and 'tags' not in f]\n",
    "        \n",
    "#         num_files = len(txt_files)\n",
    "#         train_split = int(num_files * 0.85)\n",
    "        \n",
    "#         # Create lists of indices for training and validation sets\n",
    "#         shuffled_indices = list(range(num_files))\n",
    "#         random.shuffle(shuffled_indices)\n",
    "#         train_indices = shuffled_indices[:train_split]\n",
    "#         val_indices = shuffled_indices[train_split:]\n",
    "\n",
    "#         print(f\"Class '{class_name}':\")\n",
    "#         print(f\"  Train indices: {len(train_indices)}\")\n",
    "#         print(f\"  Val indices: {len(val_indices)}\")\n",
    "\n",
    "#         # Copy files into 'train' and 'val' directories\n",
    "#         for i in train_indices:\n",
    "#             txt_file = txt_files[i]\n",
    "#             img_file = txt_file.replace('.txt', '.jpg')  # Assume corresponding .jpg files\n",
    "            \n",
    "#             # Source paths\n",
    "#             src_txt_path = os.path.join(class_path, txt_file)\n",
    "#             src_img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "#             # Destination paths\n",
    "#             dest_txt_path = os.path.join(output_train_dir, class_name, txt_file)\n",
    "#             dest_img_path = os.path.join(output_train_dir, class_name, img_file)\n",
    "            \n",
    "#             # Copy the files\n",
    "#             os.makedirs(os.path.join(output_train_dir, class_name), exist_ok=True)\n",
    "#             shutil.copy2(src_txt_path, dest_txt_path)\n",
    "#             if os.path.exists(src_img_path):\n",
    "#                 shutil.copy2(src_img_path, dest_img_path)\n",
    "\n",
    "#         for i in val_indices:\n",
    "#             txt_file = txt_files[i]\n",
    "#             img_file = txt_file.replace('.txt', '.jpg')  # Assume corresponding .jpg files\n",
    "            \n",
    "#             # Source paths\n",
    "#             src_txt_path = os.path.join(class_path, txt_file)\n",
    "#             src_img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "#             # Destination paths\n",
    "#             dest_txt_path = os.path.join(output_val_dir, class_name, txt_file)\n",
    "#             dest_img_path = os.path.join(output_val_dir, class_name, img_file)\n",
    "            \n",
    "#             os.makedirs(os.path.join(output_val_dir, class_name), exist_ok=True)\n",
    "            \n",
    "#             # Copy the files\n",
    "#             shutil.copy2(src_txt_path, dest_txt_path)\n",
    "#             if os.path.exists(src_img_path):\n",
    "#                 shutil.copy2(src_img_path, dest_img_path)\n",
    "\n",
    "# print(\"File copying complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User loop for eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the source directory containing class-specific folders\n",
    "print(output_dir)\n",
    "\n",
    "# Define the output directories for training and validation\n",
    "output_train_dir = './data/datasets/may/train'\n",
    "output_val_dir = './data/datasets/may/val'\n",
    "\n",
    "# Create the output directories if they don't exist\n",
    "os.makedirs(output_train_dir, exist_ok=True)\n",
    "os.makedirs(output_val_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each class-specific folder\n",
    "for class_name in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_name)\n",
    "    \n",
    "    if os.path.isdir(class_path):\n",
    "        # List of all .txt files (excluding those with 'tags' in their name)\n",
    "        txt_files = [f for f in os.listdir(class_path) if f.endswith('.txt') and 'tags' not in f]\n",
    "        \n",
    "        num_files = len(txt_files)\n",
    "        train_split = int(num_files * 0.85)\n",
    "        \n",
    "        # Create lists of indices for training and validation sets\n",
    "        shuffled_indices = list(range(num_files))\n",
    "        random.shuffle(shuffled_indices)\n",
    "        train_indices = shuffled_indices[:train_split]\n",
    "        val_indices = shuffled_indices[train_split:]\n",
    "\n",
    "        print(f\"Class '{class_name}':\")\n",
    "        print(f\"  Train indices: {len(train_indices)}\")\n",
    "        print(f\"  Val indices: {len(val_indices)}\")\n",
    "\n",
    "        # Copy files into 'train' and 'val' directories\n",
    "        for i in train_indices:\n",
    "            txt_file = txt_files[i]\n",
    "            img_file = txt_file.replace('.txt', '.jpg')  # Assume corresponding .jpg files\n",
    "            \n",
    "            # Source paths\n",
    "            src_txt_path = os.path.join(class_path, txt_file)\n",
    "            src_img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            # Destination paths\n",
    "            dest_txt_path = os.path.join(output_train_dir, class_name, txt_file)\n",
    "            dest_img_path = os.path.join(output_train_dir, class_name, img_file)\n",
    "            \n",
    "            # Copy the files\n",
    "            os.makedirs(os.path.join(output_train_dir, class_name), exist_ok=True)\n",
    "            shutil.copy2(src_txt_path, dest_txt_path)\n",
    "            if os.path.exists(src_img_path):\n",
    "                shutil.copy2(src_img_path, dest_img_path)\n",
    "\n",
    "        for i in val_indices:\n",
    "            txt_file = txt_files[i]\n",
    "            img_file = txt_file.replace('.txt', '.jpg')  # Assume corresponding .jpg files\n",
    "            \n",
    "            # Source paths\n",
    "            src_txt_path = os.path.join(class_path, txt_file)\n",
    "            src_img_path = os.path.join(class_path, img_file)\n",
    "            \n",
    "            # Destination paths\n",
    "            dest_txt_path = os.path.join(output_val_dir, class_name, txt_file)\n",
    "            dest_img_path = os.path.join(output_val_dir, class_name, img_file)\n",
    "            \n",
    "            os.makedirs(os.path.join(output_val_dir, class_name), exist_ok=True)\n",
    "            \n",
    "            # Copy the files\n",
    "            shutil.copy2(src_txt_path, dest_txt_path)\n",
    "            if os.path.exists(src_img_path):\n",
    "                shutil.copy2(src_img_path, dest_img_path)\n",
    "\n",
    "print(\"File copying complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
